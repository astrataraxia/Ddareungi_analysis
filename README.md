# 서울시 공공자전거 '따릉이' 이용 패턴 데이터 분석

서울시 공공자전거 '따릉이'의 운영 효율성을 높이고, 잠재적인 문제점을 파악하여 해결 방안을 모색하기 위한 데이터 분석 프로젝트입니다. 방대한 따릉이 대여 이력 데이터를 기반으로 이용자의 패턴을 심층적으로 분석하고, 그 결과를 인터랙티브 대시보드로 시각화하여 직관적인 인사이트를 제공합니다.

## 🛠️ 사용 라이브러리

-   **데이터 처리 및 분석**: `pandas`, `numpy`, `pyarrow`
-   **데이터 시각화**: `matplotlib`, `seaborn`, `altair`, `folium`
-   **웹 대시보드**: `streamlit`
-   **개발 환경**: `uv`

## 📊 데이터 분석 내용

본 프로젝트에서는 다음과 같은 핵심적인 분석을 수행합니다.

1.  **시간 기반 이용 패턴 분석**: 월별, 요일별, 시간대별 이용량 추이를 분석하여 수요가 집중되는 시기를 파악합니다.
2.  **이용 시간 및 거리 관계 분석**: 따릉이의 주된 이용 목적이 단거리 이동인지, 장거리 레저용인지 등을 파악하기 위해 이용 시간과 거리 간의 상관관계를 분석합니다.
3.  **이용 행태 및 주요 경로 분석**: 편도와 왕복 이용 비율을 통해 '교통수단'으로서의 역할과 '레저'로서의 역할을 구분하고, 시민들의 주요 이동 경로(출퇴근, 통학 등)와 레저 코스를 식별합니다.
4.  **대여소 중심 분석**: 가장 이용이 많은 인기 대여소를 파악하고, 대여와 반납의 불균형으로 발생하는 '자전거 쏠림 현상'(특정 대여소에 자전거가 몰리거나 부족해지는 현상)을 분석하여 효율적인 자전거 재배치 전략의 근거를 마련합니다.
5.  **인구 데이터 연관성 분석**: 서울시 인구 증감 추세와 따릉이 연간 수요 변화를 비교하여 두 지표 간의 연관성을 분석합니다.

## 📝 사용한 Data-set

분석에는 다음과 같은 데이터셋이 사용되었습니다.

-   서울시 공공자전거 대여이력 정보 (2020년 ~ 2025년)
-   공공자전거 대여소 마스터 정보
-   서울시 주민등록인구 통계

> **[➡️ 자세한 데이터 명세(Data Specification) 확인하기](./specs/data-model.md)**

## 📈 시각화 내용

분석 결과는 사용자가 직접 상호작용하며 탐색할 수 있는 **Streamlit 기반 인터랙티브 대시보드**를 통해 제공됩니다.

-   **시간 분석**: 연도별 월간 이용량 추이 비교, 특정일의 시간대별 이용량 비교 등
-   **거리/시간 분석**: 연도별 평균 이용 시간 및 거리 변화, 주중/주말 패턴 비교 등
-   **지리 정보 분석**:
    -   **대여소 분석**: 인기 대여소 Top 20, 자전거 유출/유입 현황, `folium`을 활용한 대여소별 순이동량 지도 시각화
    -   **경로 분석**: 편도/왕복 이용 비율, 인기 왕복/편도 경로, `folium`을 활용한 주요 이동 경로 및 핫스팟 지도 시각화

## 📂 프로젝트 구조

```
project_root/
├── data/              # 원본 및 가공 데이터
│   ├── parquet/       # Parquet으로 변환된 원본 데이터
│   ├── 01/, 02/, ...  # 분석용 데이터 마트
│   └── ...
├── src/               # 전체 소스 코드
│   ├── translate_data/  # 원본 데이터 표준화 및 변환
│   ├── data_mart/     # 데이터 마트 생성 (ETL)
│   ├── load_data/     # 데이터 로딩 모듈
│   ├── analyse/       # 심층 분석 및 정적 시각화 스크립트
│   ├── pages/         # Streamlit 페이지별 UI 및 시각화
│   └── main.py        # Streamlit 메인 앱
├── specs/             # 프로젝트 기획 및 설계 문서
└── README.md          # 프로젝트 소개
```

-   **`translate_data`**: 연도별, 월별로 나뉘어 있고 컬럼 구조가 다른 원본 CSV 파일들을 표준화된 컬럼으로 통합합니다. 특히, 매우 큰 데이터 크기를 효율적으로 다루기 위해 모든 원본 데이터를 **메모리 효율적인 Parquet 형식으로 변환**하는 역할을 담당합니다.
-   **`data_mart`**: 표준화된 Parquet 데이터를 실제 분석에 사용하기 용이한 형태(시간대별, 거리/시간별, 대여소/경로별 등)로 미리 집계하고 가공(ETL)하여 분석용 데이터 마트를 생성합니다.
-   **`load_data`**: 각 분석 모듈과 시각화 페이지에서 필요한 데이터를 효율적으로 로드하는 함수를 모아놓은 모듈입니다.
-   **`analyse`**: 독립적인 환경에서 특정 주제에 대한 심층 분석을 수행하고 정적 시각화 결과물을 생성하는 스크립트입니다.
-   **`pages`**: Streamlit 대시보드의 각 분석 페이지를 구성하는 파일들로, 사용자와의 상호작용 및 동적 시각화를 담당합니다.

---
**분석 자료 출처**: 

[서울시 따릉이 대여소별 대여/반납 승객수 정보](https://data.seoul.go.kr/dataList/OA-21229/F/1/datasetView.do)

[서울시 따릉이대여소 마스터 정보](https://data.seoul.go.kr/dataList/OA-21235/S/1/datasetView.do)

[서울시 등록인구 통계](https://data.seoul.go.kr/dataList/419/S/2/datasetView.do)