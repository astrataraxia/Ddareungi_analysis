import pandas as pd
import os
import glob
import time
import pyarrow.parquet as pq 

# --- ì„¤ì • (Configuration) ---

# 1. ì…ë ¥: ì›”ë³„ Parquet íŒŒì¼ì´ ìˆëŠ” ê¸°ë³¸ ê²½ë¡œ
BASE_INPUT_DIR = 'data/parquet'

# 2. ì¶œë ¥: ìµœì¢… ìš”ì•½ íŒŒì¼ì„ ì €ì¥í•  ê²½ë¡œ
OUTPUT_DATA_DIR = 'data/summary'

# 3. ì²˜ë¦¬í•  ì—°ë„ ë²”ìœ„
YEARS_TO_PROCESS = range(2020, 2026)

# 4. ì§‘ê³„ì— í•„ìš”í•œ ìµœì†Œí•œì˜ ì»¬ëŸ¼
REQUIRED_COLUMNS = ['ê¸°ì¤€_ë‚ ì§œ', 'ê¸°ì¤€_ì‹œê°„ëŒ€', 'ì „ì²´_ê±´ìˆ˜']


def create_yearly_summaries_from_monthly_files(year):
    """
    ì§€ì •ëœ ì—°ë„ì˜ ëª¨ë“  ì›”ë³„ Parquet íŒŒì¼ì„ ì§ì ‘ ì½ì–´, ë‘ ì¢…ë¥˜ì˜ ì‚¬ì „ ì§‘ê³„ëœ
    ìš”ì•½ íŒŒì¼(Data Mart)ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    # --- 1. ì…ë ¥ íŒŒì¼ íƒìƒ‰ ---
    year_input_folder = os.path.join(BASE_INPUT_DIR, str(year))
    file_pattern = os.path.join(year_input_folder, f'bycle_{year}*.parquet')
    monthly_files = sorted(glob.glob(file_pattern))

    if not monthly_files:
        print(f"    â© ì›ë³¸ íŒŒì¼ ì—†ìŒ: {year_input_folder} í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print(f"    - Step 1: ì´ {len(monthly_files)}ê°œì˜ ì›”ë³„ íŒŒì¼ì„ ì½ì–´ ì§‘ê³„ ì‹œì‘...")
    
    daily_hourly_dict = {}
    monthly_dict = {}
    total_chunks_processed = 0

    # --- 2. ëª¨ë“  ì›”ë³„ íŒŒì¼ì„ ìˆœíšŒí•˜ë©° ì²­í¬ ë‹¨ìœ„ë¡œ ì§‘ê³„ ---
    for file_path in monthly_files:
        try:
            parquet_file = pq.ParquetFile(file_path)
            batch_iterator = parquet_file.iter_batches(batch_size=500_000, columns=REQUIRED_COLUMNS)

            for batch in batch_iterator:

                chunk = batch.to_pandas()

                chunk['ê¸°ì¤€_ë‚ ì§œ'] = pd.to_datetime(chunk['ê¸°ì¤€_ë‚ ì§œ'], format='%Y%m%d')
                chunk['year'] = chunk['ê¸°ì¤€_ë‚ ì§œ'].dt.year
                chunk['month'] = chunk['ê¸°ì¤€_ë‚ ì§œ'].dt.month
                chunk['day'] = chunk['ê¸°ì¤€_ë‚ ì§œ'].dt.day
                chunk['hour'] = chunk['ê¸°ì¤€_ì‹œê°„ëŒ€'] // 100

                # ì§‘ê³„ 1: ì¼ë³„/ì‹œê°„ë³„
                daily_chunk_summary = chunk.groupby(['year', 'month', 'day', 'hour'])['ì „ì²´_ê±´ìˆ˜'].sum()
                for (y, m, d, h), count in daily_chunk_summary.items():
                    key = (y, m, d, h)
                    daily_hourly_dict[key] = daily_hourly_dict.get(key, 0) + count

                # ì§‘ê³„ 2: ì›”ë³„
                monthly_chunk_summary = chunk.groupby(['year', 'month'])['ì „ì²´_ê±´ìˆ˜'].sum()
                for (y, m), count in monthly_chunk_summary.items():
                    key = (y, m)
                    monthly_dict[key] = monthly_dict.get(key, 0) + count
                    
                total_chunks_processed += 1
                print(f"\r      ì´ {total_chunks_processed}ê°œì˜ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ... ({os.path.basename(file_path)})", end="")

        except Exception as e:
            file_name = os.path.basename(file_path)
            print(f"\n    âŒ ì˜¤ë¥˜: {file_name} íŒŒì¼ì„ ì½ëŠ” ì¤‘ ë¬¸ì œ ë°œìƒ - {e}. ì´ íŒŒì¼ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

    print("\n    - Step 2: ìµœì¢… ì§‘ê³„ ê²°ê³¼ ë³€í™˜ ë° ì €ì¥...")
    
    # --- ê²°ê³¼ 1: ì¼ë³„/ì‹œê°„ë³„ ìš”ì•½ íŒŒì¼ ì €ì¥ ---
    if daily_hourly_dict:
        daily_data = []
        for (y, m, d, h), count in daily_hourly_dict.items():
            daily_data.append({'year': y, 'month': m, 'day': d, 'hour': h, 'total_rentals': count})
        daily_df = pd.DataFrame(daily_data)
        
        for col in ['year', 'month', 'day', 'hour']:
            daily_df[col] = pd.to_numeric(daily_df[col], downcast='integer')
        daily_df['total_rentals'] = pd.to_numeric(daily_df['total_rentals'], downcast='unsigned')

        output_daily_file = os.path.join(OUTPUT_DATA_DIR, f'summary_daily_hourly_{year}.parquet')
        daily_df.to_parquet(output_daily_file, index=False)
        print(f"    âœ… ì¼ë³„/ì‹œê°„ë³„ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {os.path.basename(output_daily_file)}")
    else:
        print("    âš ï¸ ì¼ë³„/ì‹œê°„ë³„ ìš”ì•½ ë°ì´í„° ì—†ìŒ.")

    # --- ê²°ê³¼ 2: ì›”ë³„ ìš”ì•½ íŒŒì¼ ì €ì¥ ---
    if monthly_dict:
        monthly_data = []
        for (y, m), count in monthly_dict.items():
            monthly_data.append({'year': y, 'month': m, 'total_rentals': count})
        monthly_df = pd.DataFrame(monthly_data)
        
        for col in ['year', 'month']:
            monthly_df[col] = pd.to_numeric(monthly_df[col], downcast='integer')
        monthly_df['total_rentals'] = pd.to_numeric(monthly_df['total_rentals'], downcast='unsigned')

        output_monthly_file = os.path.join(OUTPUT_DATA_DIR, f'summary_monthly_{year}.parquet')
        monthly_df.to_parquet(output_monthly_file, index=False)
        print(f"    âœ… ì›”ë³„ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {os.path.basename(output_monthly_file)}")
    else:
        print("    âš ï¸ ì›”ë³„ ìš”ì•½ ë°ì´í„° ì—†ìŒ.")


def main():
    start_time = time.time()
    print("--- ğŸš€ ìµœì¢… ì‚¬ì „ ì§‘ê³„ ë°ì´í„° ë§ˆíŠ¸ 2ì¢… ìƒì„± ì‹œì‘ (ì›”ë³„ íŒŒì¼ ì§ì ‘ ì²˜ë¦¬) ---\n")
    
    os.makedirs(OUTPUT_DATA_DIR, exist_ok=True)
    
    for year in YEARS_TO_PROCESS:
        print(f"--- ğŸ­ {year}ë…„ ë°ì´í„° ì§‘ê³„ ì‹œì‘ ---")
        create_yearly_summaries_from_monthly_files(year)
        print("-" * 40)

    end_time = time.time()
    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
    print(f"ì§‘ê³„ëœ ìµœì¢… ìš”ì•½ íŒŒì¼ë“¤ì€ '{OUTPUT_DATA_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()